 \documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
%\usepackage{hyphenat}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage[binary-units=true]{siunitx}
\usepackage{ulem}
%\usepackage{censor}
\usepackage[table]{xcolor}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tabularx}

\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{listings}
\usepackage{dingbat}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=blue,
    filecolor=black,
    urlcolor=blue}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
\begin{document}

\newcommand{\fslspm}{FSL-SPM\xspace}
\newcommand{\fslafni}{FSL-AFNI\xspace}
\newcommand{\afnispm}{AFNI-SPM\xspace}


\title{Comparing tool variability and numerical variability in fMRI analyses}

\author{Ali Salari$^1$, Other Authors$^1$, Tristan Glatard$^1$ \\ 
$^1$ Department of Computer-Science and Software Engineering, Concordia University, Montreal, Canada}

\maketitle
\begin{abstract}

Computational environments are known to affect the pipeline results in neuroimaging,
presumably due to the creation, propagation, and amplification of small numerical errors.
Numerical instability is a characteristic of the pipelines which amplify numerical errors
originating in floating-point computations and then hamper reproducibility of the analyses.
% It has been widely investigated that methodological flexibility can influence the final determined areas of brain activation.
In particular, errors that highlight numerical instabilities are likely to appear as a result of changes in data analysis software packages.
This work presents a comparative assessment of the group-level fMRI analysis between tool variability and numerical variability.   
We characterize the effect of numerical perturbations on the fMRI analysis using the Fuzzy Libmath (FL) framework.
FL is a technique to instrument the mathematical functions embedded in mathematical libraries based on the Monte-Carlo Arithmetic (MCA).
We show that by taking advantage of the Fuzzy libmath framework, one can evaluate the numerical uncertainty of the pipelines. 
We (1) evaluated the numerical stability of the fMRI analysis that has been reproduced using three of the most common tools in neuroimaging, FSL, AFNI, and SPM,
and (2) compared between tool variability and numerical variability.
We found a significant numerical variability on both thresholded and unthresholded images;
results show that the order of magnitude of variations between tools was highly more than numerical variability.
Also, we found a linear correlation between Dice scores computed region-by-region on thresholded maps in both conditions.


\end{abstract}

\begin{IEEEkeywords}
  Numerical Instability, Reproducibility, Monte-Carlo Arithmetic, Neuroimaging
\end{IEEEkeywords}


\section{Introduction}

% Data analysis workflows in many scientific domains have become increasingly complex and flexible. 
Recent studies highlighted the instability of the neuroimaging pipelines depending on the computing platform,
software package, and even tool versions. Changes in the computational
environment such as compilers, libraries, operating systems may introduce small numerical errors and create
significantly different results in unstable pipelines~\cite{Glatard2015,Gronenschild2012,salari2020spot}.
Moreover, the impact of methodological changes on fMRI analyses has been investigated extensively~\cite{bowring2019exploring,botvinik2020variability,bhagwat2021understanding,carp2012plurality}.
For instance, in related works, it has been shown that running the same fMRI experiments by different teams can substantially affect
scientific conclusions~\cite{botvinik2020variability,carp2012plurality};
replication of fMRI experiments using the three most well-known software packages can influence the final determining areas of
brain activations~\cite{bowring2019exploring};%bowring2021isolating. 
also, the choice of preprocessing pipelines on neuroimaging cortical surface analyses is compound with the instabilities~\cite{bhagwat2021understanding}.
% In the presence of such instabilities, it is often hard to trust the data processing results. % validity of the computational results.

In such a heterogeneous environment, numerical instability is an essential issue for reproducibility.
Numerical instability is a characteristic of pipelines that results from the influence of the floating-point arithmetics
and iterative convergence of numerical errors~\cite{freitas2002issue}.
Stochastic arithmetic approaches such as Monte-Carlo Arithmetic (MCA)~\cite{Parker1997-qq} have been used to study the impact of numerical errors
originating in floating-point computations in mathematical libraries.
In~\cite{salari2021accurate}, we quantified the numerical stability of the HCP preprocessing pipeline~\cite{glasser2013} based on the MCA method by creating a Fuzzy environment
, so that instrument mathematical functions are implemented in mathematical system libraries.
As a result of numerical perturbations, we discovered a very low numerical precision in the result images comparable to the operating system variability.
In a related study~\cite{kiar2020numerical}, the instability of results was explored by instrumenting a connectome estimation pipeline with the MCA technique.
These works demonstrate the necessity of numerical uncertainty quantification for understanding related issues that hamper the computational reproducibility of analyses.

In this work, we reproduce an fMRI experiment with different neuroimaging software packages in the presence of the Fuzzy environment,
and then quantify the numerical variability and between tool variability in the results. 
The primary objective of this study is to answer these two questions: 1) how the fMRI analyses across tools are numerically stable?
2) how the numerical variability is in comparison with the tool variability?
This comparative study reveals the importance of numerical variability and motivates research studies to evaluate the numerical uncertainty of the pipelines.
  
% We start to reproduce an analysis from Bowring, this can be as a practice for reproducibility manner in the community.
% In particular, we investigate the effect of 1) between software 2) within software (numerical)
% We present a comparative assessment of group-level analysis of an fMRI pipeline.   


\section{Materials and Methods}

\subsection{Fuzzy libmath environment}

To simulate the machine-level uncertainty, we used the method introduced in~\cite{salari2021accurate} called Fuzzy libmath (FL).
FL uses Monte Carlo Arithmetic (MCA) to introduce a controlled amount of noise in the floating-point operations
through the following perturbation model:
\begin{equation} \label{eq:mca_inexact}
  inexact(x) = x + 2^{e_x-t}\xi
\end{equation}
where $e_x$ is the exponent in the floating-point representation of $x$,
$t$ is the virtual precision, the number of bits in mantissa that will not be perturbed,
and $\xi$ is a random uniform variable of $(-\frac{1}{2}, \frac{1}{2})$.
The perturbation is applied in a given number of least-significant bits,
which models floating-point rounding and catastrophic cancellation errors.
This is automated using Verificarlo tool~\cite{denis2015verificarlo} that implements MCA in the compilation time.

With the goal of OS-level perturbations, this framework instruments mathematical functions embedded
in the mathematical library in GNU operating systems, libmath.
To avoid some pitfalls in deterministic arithmetics like producing results out of the function definition,
FL instruments the functions by wrapping them so that only the original functions' output
is perturbed instead of input or their implementation.
This is achieved by adding a floating-point zero to the output of the original function so that the result of this summation
is perturbed and returned.
Listing~\ref{algo:wrapper} shows an example of this wrapping for the log function in both single and double precisions.
In this script, the original functions are called by \texttt{dlsym}, a function that returns the memory address of a symbol
using the handle of \texttt{RTLD\_NEXT}.
This allows one to provide a wrapper around a function in another shared library. 

% \lstdefinestyle{customc}{
%   belowcaptionskip=1\baselineskip,
%   breaklines=true,
%   frame=L,
%   xleftmargin=\parindent,
%   language=C,
%   showstringspaces=false,
%   basicstyle=\footnotesize\ttfamily,
%   keywordstyle=\bfseries\color{green!40!black},
%   commentstyle=\itshape\color{purple!40!black},
%   identifierstyle=\color{blue},
%   stringstyle=\color{orange},
% }

\lstdefinestyle{customasm}{
  belowcaptionskip=1\baselineskip,
  frame=L,
  xleftmargin=\parindent,
  language=[x86masm]Assembler,
  basicstyle=\footnotesize\ttfamily,
  commentstyle=\itshape\color{purple!40!black},
}
\lstinputlisting[caption=Sample wrapper script, label=algo:wrapper, style=customasm]{wrapper.c}
%\lstinputlisting[caption=Scheduler, style=customc]{../wrapper2.c}


Finally, the instrumented functions are loaded in the pipeline using LD\_PRELOAD, a Linux environment variable
to force load a shared library into an executable.
This allows functions defined in FL to transparently
overload the original ones without the need to modify or recompile the analysis pipeline.

This technique allows measuring the effect of numerical variability by running a program multiple times
with the feature of controlling the magnitude of the perturbations as perceived by the application.
Moreover, FL enables us to assess the software packages that are dynamically linked to the mathematical libraries.
So, it is important to trace the tool dependencies of the pipelines to ensure that the specific mathematical library
is involved during the pipeline executions.

% MCA allows for three perturbation modes: Random Rounding (RR) introduces the
% perturbation in function outputs, simulating roundoff errors; Precision Bounding
% (PB) introduces the perturbation in function operands, allowing for the
% detection of catastrophic cancellations; and, Full MCA combines RR and PB,
% resulting in the following perturbation:
% \begin{equation} \label{eq:mca_modes}
%   mca\_mode(x \circ y) = inexact_{RR}(  inexact_{PB}(x) \circ inexact_{PB}(y) )
% \end{equation}


\subsection{fMRI analysis \& Dataset}

We replicated the fMRI analysis described as study `ds000001' in~\cite{bowring2019exploring}
with the publicly available data repository in~\href{https://openneuro.org/datasets/ds000001}{OpenNeuro}
using the three well-known software packages for fMRI data processing, including
FSL~\cite{jenkinson2012fsl}, AFNI~\cite{cox1996afni}, and SPM~\cite{penny2011statistical}.
We selected this publication to replicate the fMRI analysis because the methods and sources were explicitly
written to be accessible and reproducible. This enabled us to reanalyze tests using the FL framework and
compare results with the between tool variability.

In the selected study, 16 healthy adult subjects participated in the balloon analog risk task to measure
risk-taking behavior over three scanning sessions.
This study included preprocessing, first-level, and second-level analyses that were implemented with all three software.
Table~\ref{table:pipeline-steps} shows the steps that were taken in the procedure of analyses for each tool in the original study.
In the original study, a number of preprocessing steps widely accepted within the community, such as motion correction,
segmentation, brain extraction, and registration, were applied in all analyses to ensure that results from each software
package could be compared objectively.
A full description of the pipelines implemented within three packages is presented in the original
study~\cite{bowring2019exploring,schonberg2012decreasing}.


%%%%%%%%%% Summary of statstics %%%%%%%%
\setlength{\tabcolsep}{4pt}
\begin{table}[h]
    \centering
    \begin{tabular}{|c|l|c|c|c|}
        \hline
%        \multirow{2}{*}{} & \multicolumn{1}{c}{Thresholded}& & \multicolumn{1}{c}{Unthresholded}& \\
        \multicolumn{2}{|c|}{} & FSL & AFNI & SPM \\
        \hline
        {Preprocessing} & {Motion Correction}                          & \checkmark    & \checkmark     & \checkmark  \\
        {} & {Segmentation}                               &    &      & \checkmark  \\
        {} & {Brain Extraction (Anatomical)}              & \checkmark     & \checkmark    & \checkmark  \\
        {} & {Brain Extraction (Functional)}              &   & \checkmark     &  \\
        {} & {Intra-subject Coregistration}               & \checkmark    & \checkmark     & \checkmark \\
        {} & {Inter-subject Registration}                 & \checkmark    & \checkmark     & \checkmark \\
        {} & {Analysis Voxel Size}                        & \checkmark    & \checkmark     & \checkmark \\
        {} & {Smoothing}                                  & \checkmark    & \checkmark     & \checkmark  \\
        \hline
        {First-level} & {Model Specification}                          & \checkmark    & \checkmark     & \checkmark  \\
        {} & {Inclusion of 6 Motion Parameters}                               & \checkmark   &  \checkmark    & \checkmark  \\
        {} & {Model Estimation}                           & &     & \checkmark  \\
        {} & {Contrasts}                                   &  \checkmark & \checkmark     & \checkmark \\
        \hline
        {Second-level} & {Model Specification}                          & \checkmark    & \checkmark     & \checkmark  \\
        {} & {Model Estimation}                           &      &    & \checkmark  \\
        {} & {Contrasts}                                   &   & \checkmark     & \checkmark  \\
        {} & {Second-level Inference}                               &  \checkmark  &    \checkmark  & \checkmark  \\
        \hline

      \end{tabular}
    \caption{Software processing steps. This table is adopted from~\cite{bowring2019exploring}.}
    \label{table:pipeline-steps}
\end{table}


\subsection{Data processing}

To capture variability between tools, the fMRI analysis pipeline was processed using three of the most popular software
packages in neuroimaging, including FSL (version 5.0.10), AFNI (version 18.1.09), and SPM (version SPM12, r7771)
on Octave (version 5.2). The analyses were conducted on the same operating system, CentOS 7.3.
% The computations were performed on a cluster comprised of ...
We ensured that the software versions and all the requisites for running analyses used in all experiments 
were similar to the original study and encapsulated in Docker images.
% We could replicate results of the original study except for AFNI with slightly differences due to the parallelization\dots
% We also used SPM/Octave instead of Matlab to be able to run analysis in HPC and also perturb mathmetical functions
% because Matlab has no dependencies on the GNU mathematical library, and it uses its libraries\dots

In addition, the same subjects and fMRI analysis were processed with the same configurations in the Fuzzy libmath environment
to produce the numerical variability results.
We only perturbed the maximum precisions to compare uncertainty between tool variability and numerical instability at the level of OS.
For this purpose, we applied instrumentations at the virtual precision (t) of 53 bits for the double-precision variable
and 24 bits for the single-precision variable. Three Fuzzy samples were generated at these precisions to match the number of tool samples.

We evaluated variabilities in (un)thresholded group-level activation maps.
We statistically computed standard deviations between T-statistic values for each pair of tools
and then compared the correlation of changes in both conditions.
The standard deviation between fuzzy samples corresponds to the square root of the summation of variances between samples in each tool.
Moreover, we determined region-by-region Dice coefficients for the thresholded maps for each pair of tools.
% This measured the overlap of acitaved voxels which assess the spatial similarity between activated maps.
The Dice values between Fuzzy samples correspond to the average pair-wise Dices computed among three Fuzzy samples
for each pair of tools.
Also, we compared the correlation of Dice scores normalized by the region sizes in both conditions.

% In this case, differences in the number of threads raised floating point rounding errors.
% So it's probabilistic to have this issue by changing the hardware architecture like variation in CPU, GPU, APU from intel, AMD, or Nvidia.
% It still may suffer from Hyper-threading (often on intel CPUs), means a physical CPU core divides into different
% virtual cores that allows more than one thread to run on each core. It says that you allocated one CPU, but virtually have multi-threads.

% EC is a means to assess whether only superficial scaling differences (differences by a scale factor over all voxels) 
% are responsible for disparities between pair of images.

\section{Results}
All scripts and results to create the figures in this section are available on GitHub repository
in \url{https://github.com/ali4006/fuzzy-neurotools}.
Replication of all analyses was visually assessed to be the same as the original study.
We ensured that fMRI analyses were processed successfully.
In this section, we call the cross-software variation and numerical variation,
between tool (BT) and within tool (WT) variability, respectively. 
The within tool variability shows results among different fuzzy libmath
samples for the specific version of the tools, and it is not within tool versions.c

A summary of the statistic values from the group-level (un)thresholded T-statistics is conducted in
Table~\ref{table:pipeline-stats}.
The variability between pair of images in each condition was measured using the mean and standard deviation of absolute differences.
Overall, the distribution of the pairwise variations in WT is an order of magnitude lower than BT in both means and standard deviations.
While the most variability was observed in the pair of \fslafni, the pair of \fslspm made the least variations for all conditions.
% Overally, we see that values in between tools are comparable to values in within tool results.


%%%%%%%%%% Summary of statstics %%%%%%%%
\setlength{\tabcolsep}{5pt}
\begin{table}[h]
    \centering
    \begin{tabular}{ccc|cc}
        \toprule
        \multirow{2}{*}{} & \multicolumn{2}{c}{Thresholded} & \multicolumn{2}{c}{Unthresholded} \\
        \cmidrule{2-3} \cmidrule{4-5} \\
        {} & Mean diff. & Std. diff. & Mean diff. & Std. diff. \\
        \midrule
        \rowcolor{lightgray}
        FSL vs. SPM          &  0.043       & 1.282      & 0.242     & 0.443  \\
        \rowcolor{lightgray}
        FSL vs. AFNI         &  0.099       & 1.548      & 0.302     & 0.547  \\
        \rowcolor{lightgray}
        AFNI vs. SPM         &  0.079       & 1.475      & 0.254     & 0.608  \\
        Fuzzy FSL and SPM    &  0.005       & 0.358      & 0.030     & 0.099  \\
        Fuzzy FSL and AFNI   &  0.011       & 0.475      & 0.038     & 0.155  \\
        Fuzzy AFNI and SPM   &  0.011       & 0.458      & 0.033     & 0.144  \\
        \bottomrule
    \end{tabular}
    \caption{Summary of T-statistics mean and standard deviation of differences for each pair of tools.}
    \label{table:pipeline-stats}
\end{table}


% \subsection{Comparing disparity in BT and WT}
%\subsection{Spatial localization of disparity in BT and WT}
\subsection{Group-level thresholded maps}

%Fig 1
Comparisons of standard deviations between thresholded images in WT and BT
on MNI space are shown in Figure~\ref{fig:thresh-varmaps}.

While we observe substantial variations in BT with the average standard deviation $\approx$ 1.5,
the order of magnitude of variations in WT is much lower with the average standard deviation $\approx$ 0.5,
as was anticipated. However, numerical variability is still significant in WT results.
%Moreover, the numerical perturbations produces variations in similar order og magnitude in WT compared to BT variations
Moreover, we see the similar order of magnitude in WT variations compared to BT variations
in some regions in the thresholded images.
For instance, some parts of the frontal lobe in the sagittal plane for almost all pairs and the occipital lobe in the axial plane
for the pairs of \fslspm and \fslafni in Figure~\ref{fig:unthresh-varmaps}
are closely replicated using the numerical perturbations. 

% Fig2
In Figure~\ref{fig:dice-thresh}, we compare region-by-region Dice coefficients of
the group-level thresholded maps for all pairs of software packages in BT and WT.
This shows a linear correlation between Dice values in BT and WT,
which implies that the variability of activated voxels in both conditions is similar.
Also, small P-values across all three pairs, including \num{1e-10} for \fslafni, \num{6e-04} for \fslspm,
and \num{2e-05} for \afnispm, confirms this correlation of similarities.
The vertical line where the Dice score is zero in BT shows regions in the brain with no overlaps between activated voxels in BT but WT,
including left/right `V1\_ROI' in \fslafni and \fslspm, and left/right `TGd\_ROI' in \afnispm results.
% The regression line is computed over Dices where BT and WT are not zero.
% The average of Dice scores range from to 
% FSL-AFNI variations has the most similarity correlations which means that the results of these two tools are more \dots

% In response to the out of border activated voxels can say:
% This is likely due to the fact that SPM consistently had the smallest analysis mask out of the three packages,
% while FSL had the largest. Number of activated voxels prove this fact.


%%%%%%%%%% Var. of Thresh %%%%%%%%
\begin{figure*}[ht]
    \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{subfigure}[t]{\textwidth}
      \centering
      \includegraphics[width=\textwidth]{figures/bt-wt-thresh-std.pdf}
      %\caption{Standard deviation of thresholded t-statistics map on template surface}
      \label{fig:thresh-varmaps1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{\textwidth}
      \centering
      \includegraphics[width=\textwidth]{figures/ratio-thresh-std.pdf}
      %\caption{Standard deviation of thresholded t-statistics map on template surface}
      \label{fig:thresh-ratiomaps}
    \end{subfigure}
    \caption{Maps of standard deviation of thresholded T-statistics. The first and second rows show
    maps on BT and WT results, respectively, and the third row represents maps of the ratio between them.}
    % so that bright blue areas indicate more similar order of magnitude of variations in both conditions,
    %and vise versa for the darkder regions.}
    \label{fig:thresh-varmaps}
    \end{minipage}}
  \end{figure*}
  

  %%%%%%%%%% Dice plot of thresholded tstats%%%%%%%%
  \begin{figure}[b]
    \fbox{\begin{minipage}{\dimexpr \columnwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[width=\columnwidth]{figures/dices_corr.png}
    \caption{Correlation of Dice coefficients of activated regions in BT and WT
    from the thresholded T-statistics. Different pairs are illustrated in different colors. 
    Regions correspond to the 360 areas of cortical parcellation (HCP-MMP1.0)~\cite{glasser2016multi}.}
    \label{fig:dice-thresh}
    \end{minipage}}
  \end{figure}



\subsection{Group-level unthresholded maps}
% \subsection{Variability of unthresholded statistical maps}

% Fig3
Figure~\ref{fig:unthresh-varmaps} shows the brain maps of standard deviations for group-level unthresholded T-statistics in WT and BT.
Results show a different magnitude of
the order of variations in WT and BT with standard deviation ranges from $\approx$ 0.12 to $\approx$ 0.5 on average, respectively.
The maps show regions in the brain where the magnitude of standard deviation is close to zero in WT but it exceeds 2.0 in BT,
such as the limbic and frontal lobes in the sagittal plane.
However, there are voxels with a significant correlation between WT and BT that are uniformly distributed across the brain maps.

%%%%%%%%%% Var. of Thresh %%%%%%%%
\begin{figure*}[b]
    \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{subfigure}[t]{\textwidth}
      \centering
      \includegraphics[width=\textwidth]{figures/bt-wt-unthresh-std.pdf}
      %\caption{Standard deviation of thresholded t-statistics map on template surface}
      \label{fig:unthresh-varmaps1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{\textwidth}
      \centering
      \includegraphics[width=\textwidth]{figures/ratio-unthresh-std.pdf}
      %\caption{Standard deviation of thresholded t-statistics map on template surface}
      \label{fig:unthresh-ratiomaps}
    \end{subfigure}
    \caption{Maps of standard deviation of unthresholded T-statistics. The first and second rows show
    maps on BT and WT results, respectively, and the third row represents maps of the ratio between them.}
    \label{fig:unthresh-varmaps}
    \end{minipage}}
  \end{figure*}
  

% Fig4
The scatter plot in Figure~\ref{fig:correlations} represents the correlation of standard deviation in WT and BT variability.
We found two major clusters, including the identity cluster that corresponds to the correlations
between BT and WT with the ratio of $0.5 < BT/WT < 1.5$,
and the upper cluster that shows voxels where BT $\approx$ 0.
The percentage of voxels included in the identity cluster is \%9.9 in \fslspm, \%17.3 in \fslafni, and \%13.8 in \afnispm,
and total voxels in the upper cluster are $\approx$ \%1.
The identity area is also represented on the MNI space in the second row in Figure~\ref{fig:correlations}.
This figure shows the spatial localization of the parts of the brain that BT variability is correlated with the numerical variability.
This refines the presented results in Figure~\ref{fig:unthresh-varmaps},
which indicates how correlation is uniformly distributed across the brain.
% Spatial localization of significant activation in the thresholded images also varied across software packages.
% Moreover, results show that pair of FSL-SPM has the least correlation of variability in within tool and between tool.
% This will implies that ... which can help for further investigations. 
  
  %%%%%%%%%% Corr. plot of tstats%%%%%%%%
  \begin{figure*}[b]
    \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
      \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/std-corr-unthresh-plot.png}
        %\caption{Standard deviation of thresholded t-statistics map on template surface}
        \label{fig:unthresh-corrplot}
      \end{subfigure}
      \hfill
      \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/corr-unthresh-std.pdf}
        %\caption{Standard deviation of thresholded t-statistics map on template surface}
        \label{fig:unthresh-corrmaps}
      \end{subfigure}
      \caption{Correlation of standard deviations in BT and WT from the unthresholded T-statistics. 
      The first row plots the correlations voxel by voxel and is highlighted with different colors
      for two clusters, including the upper cluster (purple color) and the correlated cluster (green color).
      The second row maps the correlated area on the MNI space.}
    \label{fig:correlations}
    \end{minipage}}
  \end{figure*}
  
  

\section{Conclusion \& Discussion}

% There are many statistical comparisons, but the neuro-scientific interpretation of results is not on my side.

\begin{itemize}
    \item[$\bullet$ ] In this study, we represented the magnitude of differences in between tool and within tool results.
    We obtained more instability in BT compared to WT. Also we showed how between tool variations
    are correlated with numerical variability.
   
    \item[$\bullet$ ] Generally, we obtained more uncertainty on thresholded results, probably due to different thresholding
    methods used in different tools. This can raise further investigations on the thresholding techniques toward stability.
  
    \item[$\bullet$ ] Further studies can be evaluating the numerical stabilities within tool by focusing on the particular parts of 
    the pipeline that has been identified as the main sources of variations in~\cite{bowring2021isolating}.
    Also, we can invetigate the precision in WT variability that simulates mostly BT variability in the furure study.
    
\end{itemize}
  

\section{Acknowledgments} 


%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{plain}
\bibliography{biblio}


\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
